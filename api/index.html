
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A Python machine learning library with automatic differentiation">
      
      
        <meta name="author" content="Adam Jamrozisnki">
      
      
      
      
      
        
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>API Reference - Autograd</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#src" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Autograd" class="md-header__button md-logo" aria-label="Autograd" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Autograd
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API Reference
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/adamJamro/pygrad" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    autograd
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
  
    
  
  API Reference

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Autograd" class="md-nav__button md-logo" aria-label="Autograd" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Autograd
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/adamJamro/pygrad" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    autograd
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#src" class="md-nav__link">
    <span class="md-ellipsis">
      
        src
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.Variable" class="md-nav__link">
    <span class="md-ellipsis">
      
        Variable
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.Variable.backward" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.Variable.constant" class="md-nav__link">
    <span class="md-ellipsis">
      
        constant
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.Variable.convolve" class="md-nav__link">
    <span class="md-ellipsis">
      
        convolve
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.Variable.log_softmax" class="md-nav__link">
    <span class="md-ellipsis">
      
        log_softmax
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable" class="md-nav__link">
    <span class="md-ellipsis">
      
        variable
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.Variable" class="md-nav__link">
    <span class="md-ellipsis">
      
        Variable
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.autodiff.variable.Variable.backward" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.autodiff.variable.Variable.constant" class="md-nav__link">
    <span class="md-ellipsis">
      
        constant
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.autodiff.variable.Variable.convolve" class="md-nav__link">
    <span class="md-ellipsis">
      
        convolve
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.autodiff.variable.Variable.log_softmax" class="md-nav__link">
    <span class="md-ellipsis">
      
        log_softmax
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable._ONES" class="md-nav__link">
    <span class="md-ellipsis">
      
        _ONES
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable._ZEROS" class="md-nav__link">
    <span class="md-ellipsis">
      
        _ZEROS
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable._image2windows" class="md-nav__link">
    <span class="md-ellipsis">
      
        _image2windows
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable._space2windows" class="md-nav__link">
    <span class="md-ellipsis">
      
        _space2windows
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable._stream2windows" class="md-nav__link">
    <span class="md-ellipsis">
      
        _stream2windows
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.activation_ReLU" class="md-nav__link">
    <span class="md-ellipsis">
      
        activation_ReLU
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.activation_log_softmax" class="md-nav__link">
    <span class="md-ellipsis">
      
        activation_log_softmax
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.activation_sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      
        activation_sigmoid
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.activation_tanh" class="md-nav__link">
    <span class="md-ellipsis">
      
        activation_tanh
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.convolve_forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        convolve_forward
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.get_tape_stack_snapshot" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_tape_stack_snapshot
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.grad" class="md-nav__link">
    <span class="md-ellipsis">
      
        grad
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="grad">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.autodiff.variable.grad--todo-currently-serves-no-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        TODO currently serves no optimization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.loss_NLL" class="md-nav__link">
    <span class="md-ellipsis">
      
        loss_NLL
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.loss_mae" class="md-nav__link">
    <span class="md-ellipsis">
      
        loss_mae
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.loss_mse" class="md-nav__link">
    <span class="md-ellipsis">
      
        loss_mse
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.operator_broadcast_to" class="md-nav__link">
    <span class="md-ellipsis">
      
        operator_broadcast_to
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.operator_flip" class="md-nav__link">
    <span class="md-ellipsis">
      
        operator_flip
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.operator_pad" class="md-nav__link">
    <span class="md-ellipsis">
      
        operator_pad
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.operator_reshape" class="md-nav__link">
    <span class="md-ellipsis">
      
        operator_reshape
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.variable.operator_sum" class="md-nav__link">
    <span class="md-ellipsis">
      
        operator_sum
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.tape" class="md-nav__link">
    <span class="md-ellipsis">
      
        tape
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.autodiff.tape.Tape" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tape
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.network.network" class="md-nav__link">
    <span class="md-ellipsis">
      
        network
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.network.network.Linear" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.network.network.Network" class="md-nav__link">
    <span class="md-ellipsis">
      
        Network
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>API Reference</h1>

<div class="doc doc-object doc-module">



<a id="src"></a>
    <div class="doc doc-contents first">

        <p>PyGrad - A neural network library with autograd automatic gradient calculation.</p>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h2 id="src.Variable" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">Variable</span>


<a href="#src.Variable" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">













<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="src.Variable.backward" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">backward</span>


<a href="#src.Variable.backward" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">backward</span><span class="p">(</span><span class="n">directional_grad</span><span class="p">:</span> <span class="n">Variable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Variable</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Convenience method to compute gradients of this variable with respect to all other variables in the graph.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.Variable.constant" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">constant</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-cached"><code>cached</code></small>
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#src.Variable.constant" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">constant</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">numeric</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>micro-optimization memoizing constant variables since they don't lead to cycles in the computation graph</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.Variable.convolve" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">convolve</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#src.Variable.convolve" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">convolve</span><span class="p">(</span><span class="n">matrix</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">kernel</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Convolve matrix with kernel, both</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.Variable.log_softmax" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">log_softmax</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#src.Variable.log_softmax" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">log_softmax</span><span class="p">(</span><span class="n">variable</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes log_softmax(x) = log(softmax(x)) = x - log(sum(exp(x)))
see the variable.activation_log_softmax() for more info</p>


    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.autodiff.variable"></a>
    <div class="doc doc-contents first">

        <p>@Author Adam Jamrozi≈Ñski</p>
<p>Variable is the building block of the computation graph
each overloaded or custom operator saves itself as a record on a tape stack</p>
<p>The _tape_stack is bundled with the variable module by default.
It contains all the information about which variable was needed to compute the other.
The information how to compute the backward partial derivative at each step.
Thanks to this approach, the list is being automatically sorted topologically (in reverse order)</p>
<p>Each variable in the computation graph can be passed to the grad(...) function to compute its derivative</p>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h2 id="src.autodiff.variable.Variable" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">Variable</span>


<a href="#src.autodiff.variable.Variable" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">













<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="src.autodiff.variable.Variable.backward" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">backward</span>


<a href="#src.autodiff.variable.Variable.backward" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">backward</span><span class="p">(</span><span class="n">directional_grad</span><span class="p">:</span> <span class="n">Variable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Variable</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Convenience method to compute gradients of this variable with respect to all other variables in the graph.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.autodiff.variable.Variable.constant" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">constant</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-cached"><code>cached</code></small>
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#src.autodiff.variable.Variable.constant" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">constant</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">numeric</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>micro-optimization memoizing constant variables since they don't lead to cycles in the computation graph</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.autodiff.variable.Variable.convolve" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">convolve</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#src.autodiff.variable.Variable.convolve" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">convolve</span><span class="p">(</span><span class="n">matrix</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">kernel</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Convolve matrix with kernel, both</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.autodiff.variable.Variable.log_softmax" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">log_softmax</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#src.autodiff.variable.Variable.log_softmax" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">log_softmax</span><span class="p">(</span><span class="n">variable</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes log_softmax(x) = log(softmax(x)) = x - log(sum(exp(x)))
see the variable.activation_log_softmax() for more info</p>


    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable._ONES" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">_ONES</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-cached"><code>cached</code></small>
  </span>

<a href="#src.autodiff.variable._ONES" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">_ONES</span><span class="p">(</span><span class="n">arr_shape</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns cached Variable of ones with a given shape and type</p>
<p>Thus this should never be a learnable parameter (must stay immutable)</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable._ZEROS" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">_ZEROS</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-cached"><code>cached</code></small>
  </span>

<a href="#src.autodiff.variable._ZEROS" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">_ZEROS</span><span class="p">(</span><span class="n">arr_shape</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns cached Variable of zeros with a given shape and type</p>
<p>Thus this should never be a learnable parameter (must stay immutable)</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable._image2windows" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">_image2windows</span>


<a href="#src.autodiff.variable._image2windows" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">_image2windows</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span> <span class="n">window_shape</span><span class="p">:</span> <span class="n">shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ndarray</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Extracts a view of sliding windows from the input image based on windws_shape.</p>
<p>Assumes no padding and up/down sliding stride of 1.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable._space2windows" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">_space2windows</span>


<a href="#src.autodiff.variable._space2windows" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">_space2windows</span><span class="p">(</span><span class="n">space</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span> <span class="n">window_shape</span><span class="p">:</span> <span class="n">shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ndarray</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Extracts a view of sliding windows from the input space based on windws_shape.
Assumes no padding and sliding stride of 1 in all dimensions.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable._stream2windows" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">_stream2windows</span>


<a href="#src.autodiff.variable._stream2windows" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">_stream2windows</span><span class="p">(</span><span class="n">stream</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span> <span class="n">window_length</span><span class="p">:</span> <span class="n">shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ndarray</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Extracts a view of sliding windows from the input 1D stream based on window_length.
Assumes no padding and left/right sliding stride of 1.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.activation_ReLU" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">activation_ReLU</span>


<a href="#src.autodiff.variable.activation_ReLU" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">activation_ReLU</span><span class="p">(</span><span class="n">var</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Element-wise Rectified Linear Unit activation function</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.activation_log_softmax" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">activation_log_softmax</span>


<a href="#src.autodiff.variable.activation_log_softmax" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">activation_log_softmax</span><span class="p">(</span><span class="n">var</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Element-wise Log(Softmax(var)) activation function along the specified axis</p>
<p>Use it with Negative-Log-Likelihood to achieve cross-entropy loss.</p>
<p>Note that for regular softmax the derivatives would have looked like
    dSoftmax_i/dInput_i = Softmax_i * (1 - Softmax_i)
    dSoftmax_i/dInput_j = -Softmax_i * Softmax_j; if i != j
however with log it simplifies to:
    dLogSoftmax_i/dInput_i = 1 - Softmax_i
    dLogSoftmax_i/dInput_j = -Softmax_j; if i != j</p>
<p>This implementation includes the standard numerical stability trick with the max subtraction.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.activation_sigmoid" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">activation_sigmoid</span>


<a href="#src.autodiff.variable.activation_sigmoid" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">activation_sigmoid</span><span class="p">(</span><span class="n">var</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Element-wise Sigmoid activation function</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.activation_tanh" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">activation_tanh</span>


<a href="#src.autodiff.variable.activation_tanh" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">activation_tanh</span><span class="p">(</span><span class="n">var</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Element-wise Tanh activation function</p>
<p>tanh(x) = (e^(x) - e^(-x)) / (e^(x) + e^(-x))</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.convolve_forward" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">convolve_forward</span>


<a href="#src.autodiff.variable.convolve_forward" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">convolve_forward</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span> <span class="n">kernel</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span> <span class="n">optimize</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s1">&#39;greedy&#39;</span><span class="p">,</span> <span class="s1">&#39;optimal&#39;</span><span class="p">]</span> <span class="o">|</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Sequence</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ndarray</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Performs a convolution operation on the input ndarray with the given kernel.</p>
<p>Matrix and Kernel must adhere to constraints.
This library version supports 1d,2d and 3d convolutions, but more dimensions are straightforward to implement.
Note that if the length of dimensions of tensor and kernel match, custom 4D, 5D, and so on sliding windows
result in the exact same backward functions!</p>
<p>This implementation does not flip the kernel, effectively performing a Convolution* a.k.a. Cross-Correlation.
Note we do not perform padding and assume a stride of 1.</p>
<p>The 'optimize' param is passed to the numpy.einsum for optimized broadcasted multiplication and reduction sum
with no optimization the broadcasting with einsum is already faster because it doesn't create copies of intermediate arrays.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.get_tape_stack_snapshot" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">get_tape_stack_snapshot</span>


<a href="#src.autodiff.variable.get_tape_stack_snapshot" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">get_tape_stack_snapshot</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tape</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>returns a snapshot shallow copy of the tape stack</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.grad" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">grad</span>


<a href="#src.autodiff.variable.grad" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">grad</span><span class="p">(</span><span class="n">loss_variable</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tape_records</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">custom_entry_gradient</span><span class="p">:</span> <span class="n">Variable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">desired_results</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Variable</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Variable</span><span class="p">,</span> <span class="n">Variable</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes gradients of the loss_variable with respect to each Variable in the computation graph,
dLoss_d lookup map effectively works out to make dLoss_d[x] equal to dLoss/dx</p>
<p>:returns
    a dictionary of the d(loss_variable)/d[key] where key is any other variable used to compute the loss_variable</p>
<p>:params
loss_variable:
    The top node of the computation graph representing the loss.
    If the loss is not a scalar, it's implicitly set to be an array of ones with the same shape as the loss.</p>


<details class="desired_results" open>
  <summary>desired_results</summary>
  <h3 id="src.autodiff.variable.grad--todo-currently-serves-no-optimization">TODO currently serves no optimization<a class="headerlink" href="#src.autodiff.variable.grad--todo-currently-serves-no-optimization" title="Permanent link">&para;</a></h3>
<p>Selects what we exclude from the gradient result list.
If desired_results is None, gradients for all variables in the computation graph will be computed.</p>
</details>        <p>If the tape does not contain a variable,
we consider its gradient None (which brings pruning of unused graoh branches to constant time checks).</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.loss_NLL" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">loss_NLL</span>


<a href="#src.autodiff.variable.loss_NLL" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">loss_NLL</span><span class="p">(</span><span class="n">log_probs</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">target_probs</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Negative Log-Likelihood Loss for classification tasks.</p>
<p>:param log_probs: Log probabilities from the model (output of log_softmax).
:param target_probs: True underlying probability indices (class labels).
:return: NLL loss variable. Combined with log_softmax gives cross-entropy loss.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.loss_mae" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">loss_mae</span>


<a href="#src.autodiff.variable.loss_mae" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">loss_mae</span><span class="p">(</span><span class="n">predicted</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">Variable</span> <span class="o">|</span> <span class="n">numeric</span> <span class="o">|</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">numeric</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Mean Absolute Error Loss between predicted and target variables.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.loss_mse" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">loss_mse</span>


<a href="#src.autodiff.variable.loss_mse" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">loss_mse</span><span class="p">(</span><span class="n">predicted</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">Variable</span> <span class="o">|</span> <span class="n">numeric</span> <span class="o">|</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">numeric</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Mean Squared Error Loss between predicted and target variables.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.operator_broadcast_to" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">operator_broadcast_to</span>


<a href="#src.autodiff.variable.operator_broadcast_to" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">operator_broadcast_to</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">broadcast_shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Broadcasts the array variable to the given shape
equivalent to numpy.broadcast_to</p>
<p>Beware this function uses numpy's view under the hood
so the result of this operator must remain immutable.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.operator_flip" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">operator_flip</span>


<a href="#src.autodiff.variable.operator_flip" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">operator_flip</span><span class="p">(</span><span class="n">matrix</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>flip the array variable along dimension
equivalent to numpy.flip</p>
<p>operator_flip(array) is equivalent to array[::-1,::-1, ..., ::-1]</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.operator_pad" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">operator_pad</span>


<a href="#src.autodiff.variable.operator_pad" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">operator_pad</span><span class="p">(</span><span class="n">matrix</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Pads the array variable according to pad_width
pad_width ~ ((before(dim), after(dim)) for dim in each dimension)</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.operator_reshape" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">operator_reshape</span>


<a href="#src.autodiff.variable.operator_reshape" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">operator_reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Reshape tensor using numpy.reshape</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="src.autodiff.variable.operator_sum" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">operator_sum</span>


<a href="#src.autodiff.variable.operator_sum" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="nf">operator_sum</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sums the elements of the tensor along the specified axis.
If axis is None, sums all elements.</p>


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.autodiff.tape"></a>
    <div class="doc doc-contents first">

        <p>The backward pass is computed via a topologically sorted stack of callbacks aka the backward pass is "tape-based".
Tape class organizes and singles out Variable's responsibility of storing the computation graph (DAG).
Additionally, it is a neat way we topologically sort the computation graph,
since the computation is going to be performed in the same order we put it on the tape.</p>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h2 id="src.autodiff.tape.Tape" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">Tape</span>


<a href="#src.autodiff.tape.Tape" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="typing.NamedTuple">NamedTuple</span></code></p>



        <p>Single tape record containing information about a single computation step in the graph</p>
<p>Remark that the back_fn callback operates on Variable instances
that entails that a new graph is being built during the backward pass</p>











<div class="doc doc-children">












  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.network.network"></a>
    <div class="doc doc-contents first">










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h2 id="src.network.network.Linear" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">Linear</span>


<a href="#src.network.network.Linear" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Network (src.network.network.Network)" href="#src.network.network.Network">Network</a></code></p>



        <p>Ready to use linear subnetwork implementation
equivalent to Wx+b linear step</p>











<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.network.network.Network" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">Network</span>


<a href="#src.network.network.Network" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="abc.ABC">ABC</span></code></p>



        <p>Modular neural network base class.</p>
<p>To use, inherit from Network e.g.:
FooNN(Network):
    <strong>init</strong>(self, ...):
        super().<strong>init</strong>()
        declared here fields either of type Variable or Network
        will be stored marked as learnable parameters
        ...
    forward(self, ...):
        ...
        overwrite of abstract forward is being required
        this function needs to return the output Variable</p>











<div class="doc doc-children">












  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/adamJamro/pygrad" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.instant", "navigation.tabs", "navigation.sections", "content.code.copy", "toc.integrate"], "search": "../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
    
  </body>
</html>